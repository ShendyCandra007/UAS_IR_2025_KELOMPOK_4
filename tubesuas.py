# -*- coding: utf-8 -*-
"""tubesgweh_modified.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11r5Eo_fVuhiaZByetLVu3MlgD5bXA5gj
"""

import streamlit as st
import os
import tarfile
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, adjusted_rand_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm

st.set_page_config(page_title="Text Clustering App", layout="wide")
st.title("Word Embedding-based Text Clustering")

st.sidebar.header("Step-by-step Controls")

# Step 1: Upload dataset
st.sidebar.subheader("1. Upload Dataset")
uploaded_file = st.sidebar.file_uploader("Upload 20 Newsgroups .tar.gz", type=["tar.gz"])

@st.cache_data
def extract_dataset(uploaded_file):
    extract_path = "/tmp/20news_extracted"
    if not os.path.exists(extract_path):
        os.makedirs(extract_path)
    with tarfile.open(fileobj=uploaded_file, mode="r:gz") as tar:
        tar.extractall(path=extract_path)
    return extract_path

@st.cache_data
def load_documents(extract_path, max_docs=1000):
    documents, labels = [], []
    for root, dirs, files in os.walk(extract_path):
        for file in files:
            try:
                with open(os.path.join(root, file), 'r', encoding='latin1') as f:
                    content = f.read()
                    label = os.path.basename(root)
                    documents.append(content)
                    labels.append(label)
                    if len(documents) >= max_docs:
                        return documents, labels
            except:
                continue
    return documents, labels

@st.cache_data
def purity_score(y_true, y_pred):
    matrix = confusion_matrix(y_true, y_pred)
    return np.sum(np.amax(matrix, axis=0)) / np.sum(matrix)

if uploaded_file:
    with st.spinner("Mengekstrak dataset..."):
        extract_path = extract_dataset(uploaded_file)

    max_docs = st.sidebar.slider("2. Jumlah Dokumen yang Digunakan", 100, 2000, 1000, step=100)
    documents, labels_true = load_documents(extract_path, max_docs=max_docs)
    st.success(f"{len(documents)} dokumen berhasil dimuat.")

    if st.checkbox("Tampilkan cuplikan dokumen"):
        st.subheader("Cuplikan Dataset")
        st.dataframe(pd.DataFrame({"Topik": labels_true[:5], "Dokumen": documents[:5]}))

    st.sidebar.subheader("3. TF-IDF Vectorization")
    max_features = st.sidebar.slider("Jumlah fitur TF-IDF", 500, 5000, 1000, step=500)
    vectorizer = TfidfVectorizer(max_features=max_features, stop_words='english')
    X = vectorizer.fit_transform(documents)

    st.sidebar.subheader("4. Clustering")
    k = st.sidebar.slider("Jumlah Cluster (KMeans)", 2, 30, 5)
    run_cluster = st.sidebar.button("Jalankan Clustering")

    if run_cluster:
        with st.spinner("Melakukan clustering..."):
            kmeans = KMeans(n_clusters=k, random_state=42)
            labels_pred = kmeans.fit_predict(X)

        from sklearn.preprocessing import LabelEncoder
        le = LabelEncoder()
        labels_encoded = le.fit_transform(labels_true)

        sil = silhouette_score(X, labels_pred)
        ari = adjusted_rand_score(labels_encoded, labels_pred)
        purity = purity_score(labels_encoded, labels_pred)

        st.subheader("Evaluasi Clustering")
        eval_df = pd.DataFrame({
            "Metric": ["Silhouette", "Adjusted Rand Index", "Purity"],
            "Score": [sil, ari, purity]
        })
        st.dataframe(eval_df)

        st.subheader("Visualisasi PCA 2D")
        from sklearn.decomposition import PCA
        X_pca = PCA(n_components=2).fit_transform(X.toarray())
        df_vis = pd.DataFrame({
            "x": X_pca[:, 0],
            "y": X_pca[:, 1],
            "Cluster": labels_pred
        })
        fig, ax = plt.subplots(figsize=(8, 5))
        sns.scatterplot(data=df_vis, x="x", y="y", hue="Cluster", palette="tab10", ax=ax)
        st.pyplot(fig)
        st.subheader("Cuplikan Dokumen Tiap Cluster")
        doc_df = pd.DataFrame({"Dokumen": documents, "Cluster": labels_pred})
        st.dataframe(doc_df.groupby("Cluster").head(2).reset_index(drop=True))

        # ⬇⬇ Tambahan ini harus tetap dalam blok if run_cluster, indent 8 spasi
        st.subheader("Deskripsi Setiap Cluster")

        df_cluster_info = pd.DataFrame({
            "Cluster": labels_pred,
            "LabelAsli": labels_true,
            "Dokumen": documents
        })

        for clust_num in sorted(df_cluster_info["Cluster"].unique()):
            cluster_docs = df_cluster_info[df_cluster_info["Cluster"] == clust_num]

            st.markdown(f"**Cluster {clust_num}**")
            st.markdown(f"- Jumlah Dokumen: {len(cluster_docs)}")

            if len(cluster_docs) < 2:
                st.markdown("- Tidak cukup dokumen untuk analisis topik.")
                st.markdown("---")
                continue

            try:
                top_label = cluster_docs["LabelAsli"].value_counts().idxmax()
                vectorizer = TfidfVectorizer(stop_words='english', max_features=20)
                vectorizer.fit(cluster_docs["Dokumen"])
                top_words = (
                    vectorizer.get_feature_names_out()
                    if hasattr(vectorizer, 'get_feature_names_out')
                    else vectorizer.get_feature_names()
                )
                st.markdown(f"- Topik Dominan (Label Asli): `{top_label}`")
                st.markdown(f"- Kata-Kata Umum: `{', '.join(top_words)}`")
            except Exception as e:
                st.markdown(f"- Gagal menganalisis kata: {e}")
            st.markdown("---")
         # Kesimpulan Naratif Hasil Clustering
        st.subheader("Kesimpulan Hasil Clustering")

        kesimpulan = ""

        # Silhouette Score Interpretation
        if sil > 0.5:
            kesimpulan += (
                f"- Nilai **Silhouette Score** sebesar **{sil:.2f}** menunjukkan bahwa dokumen-dokumen dalam masing-masing cluster memiliki kemiripan tinggi dan cukup terpisah dari cluster lain. Ini menandakan struktur clustering cukup baik dan stabil.\n\n"
            )
        elif sil > 0.25:
            kesimpulan += (
                f"- Nilai **Silhouette Score** sebesar **{sil:.2f}** mengindikasikan bahwa hasil clustering masih bisa ditingkatkan. Beberapa dokumen mungkin tidak cocok dengan cluster-nya atau ada overlap antar cluster.\n\n"
            )
        else:
            kesimpulan += (
                f"- Nilai **Silhouette Score** rendah (**{sil:.2f}**) menunjukkan pemisahan cluster yang lemah. Disarankan untuk meninjau kembali jumlah cluster atau metode embedding yang digunakan.\n\n"
            )

        # ARI Interpretation
        if ari > 0.5:
            kesimpulan += (
                f"- **Adjusted Rand Index (ARI)** sebesar **{ari:.2f}** menunjukkan kesesuaian yang baik antara hasil clustering dengan label asli. Ini berarti model berhasil mengelompokkan dokumen ke dalam topik yang relevan.\n\n"
            )
        elif ari > 0.25:
            kesimpulan += (
                f"- Nilai **ARI** sebesar **{ari:.2f}** menunjukkan kesesuaian sedang antara hasil cluster dan label asli. Beberapa dokumen mungkin tertukar antar cluster.\n\n"
            )
        else:
            kesimpulan += (
                f"- **ARI** rendah (**{ari:.2f}**) menandakan bahwa hasil clustering tidak merepresentasikan struktur topik asli dengan baik. Model perlu ditingkatkan atau jumlah cluster disesuaikan.\n\n"
            )

        # Purity Interpretation
        if purity > 0.8:
            kesimpulan += (
                f"- **Purity** sebesar **{purity:.2f}** mengindikasikan bahwa sebagian besar dokumen dalam setiap cluster berasal dari topik yang sama. Cluster memiliki kualitas yang tinggi dalam memisahkan topik.\n\n"
            )
        elif purity > 0.6:
            kesimpulan += (
                f"- Nilai **Purity** sebesar **{purity:.2f}** menunjukkan bahwa beberapa cluster masih memiliki dokumen dari topik berbeda, tetapi cukup layak untuk interpretasi awal.\n\n"
            )
        else:
            kesimpulan += (
                f"- **Purity** rendah (**{purity:.2f}**) berarti cluster banyak berisi dokumen dari berbagai topik, sehingga sulit untuk mendapatkan makna topik yang jelas dari masing-masing cluster.\n\n"
            )

        st.markdown(kesimpulan)

        # Nilai tetap dari paper (dataset 20NG)
        paper_scores = [
        {"Metode": "WEClustering (K)", "Silhouette": 0.130, "ARI": 0.344, "Purity": 0.637},
        {"Metode": "WEClustering (A)", "Silhouette": 0.110, "ARI": 0.264, "Purity": 0.600},
        {"Metode": "KMeans (Paper)", "Silhouette": 0.002, "ARI": 0.272, "Purity": 0.607},
        {"Metode": "Model Kami", "Silhouette": sil, "ARI": ari, "Purity": purity}
    ]

        df_compare = pd.DataFrame(paper_scores)
        st.dataframe(df_compare)

        # Optional: Visualisasi grafik batang
        st.subheader("Visualisasi Perbandingan Performa")

        fig, ax = plt.subplots(1, 3, figsize=(18, 5))
        sns.barplot(data=df_compare, x="Metode", y="Silhouette", ax=ax[0])
        ax[0].set_title("Silhouette Score")

        sns.barplot(data=df_compare, x="Metode", y="ARI", ax=ax[1])
        ax[1].set_title("Adjusted Rand Index (ARI)")

        sns.barplot(data=df_compare, x="Metode", y="Purity", ax=ax[2])
        ax[2].set_title("Purity")

        for a in ax:
            a.set_xticklabels(a.get_xticklabels(), rotation=15)

        st.pyplot(fig)